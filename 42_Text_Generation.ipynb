{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vepNlhS_h7Hd",
        "outputId": "7f08219a-16b7-457b-a97c-acfd04c8035f"
      },
      "source": [
        "### Install necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vgQB5dvqi2yc"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use the GPT2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Define a function that generates text based on the input\n",
        "def generate_text(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id).float()\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, attention_mask=attention_mask)\n",
        "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    print(output_text)\n",
        "\n",
        "\n",
        "# Create an interactive widget\n",
        "input_text_widget = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Type something',\n",
        "    description='Input text:',\n",
        "    layout=widgets.Layout(width=\"auto\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ4HTG2CiMmF"
      },
      "source": [
        "### Example input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_input = \"I thought to not to go there but I had to, why I had no dreams \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxT62J_RiZHU",
        "outputId": "f2715b22-a5bd-4b65-9101-479a52e74c45"
      },
      "source": [
        "### Call the function with the example input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_text(example_input)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

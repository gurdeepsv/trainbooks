{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Import Required Libraries\n",
    "Import the necessary libraries, including matplotlib, keras, numpy, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Load and Subset MNIST Dataset\n",
    "Load the MNIST dataset and create a subset for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of subset training data: 600\n",
      "Length of subset testing data: 100\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Create a new subset dataset\n",
    "subset_train_indices = []\n",
    "subset_test_indices = []\n",
    "for class_label in range(10):\n",
    "    class_indices = np.where(y_train == class_label)[0]\n",
    "    subset_train_indices.extend(class_indices[:60])\n",
    "    class_indices = np.where(y_test == class_label)[0]\n",
    "    subset_test_indices.extend(class_indices[60:70])\n",
    "\n",
    "X_train = X_train[subset_train_indices]\n",
    "y_train = y_train[subset_train_indices]\n",
    "X_test = X_test[subset_test_indices]\n",
    "y_test = y_test[subset_test_indices]\n",
    "\n",
    "# Display the length of each part\n",
    "print(f\"Length of subset training data: {len(X_train)}\")\n",
    "print(f\"Length of subset testing data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Display Dataset Information\n",
    "Display the length of the subset training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of class 0 in training data: 60\n",
      "Sum of class 1 in training data: 60\n",
      "Sum of class 2 in training data: 60\n",
      "Sum of class 3 in training data: 60\n",
      "Sum of class 4 in training data: 60\n",
      "Sum of class 5 in training data: 60\n",
      "Sum of class 6 in training data: 60\n",
      "Sum of class 7 in training data: 60\n",
      "Sum of class 8 in training data: 60\n",
      "Sum of class 9 in training data: 60\n",
      "Sum of class 0 in testing data: 10\n",
      "Sum of class 1 in testing data: 10\n",
      "Sum of class 2 in testing data: 10\n",
      "Sum of class 3 in testing data: 10\n",
      "Sum of class 4 in testing data: 10\n",
      "Sum of class 5 in testing data: 10\n",
      "Sum of class 6 in testing data: 10\n",
      "Sum of class 7 in testing data: 10\n",
      "Sum of class 8 in testing data: 10\n",
      "Sum of class 9 in testing data: 10\n",
      "Length of subset training data: 600\n",
      "Length of subset testing data: 100\n"
     ]
    }
   ],
   "source": [
    "# Print the sum of each class label in the training data\n",
    "for i in range(10):\n",
    "    print(f\"Sum of class {i} in training data: {sum(y_train == i)}\")\n",
    "\n",
    "# Print the sum of each class label in the testing data\n",
    "for i in range(10):\n",
    "    print(f\"Sum of class {i} in testing data: {sum(y_test == i)}\")\n",
    "\n",
    "# Display the length of each part\n",
    "print(f\"Length of subset training data: {len(X_train)}\")\n",
    "print(f\"Length of subset testing data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Shift Images in Dataset\n",
    "Randomly shift the images in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Images in Dataset\n",
    "X_shifted = np.copy(X_train)\n",
    "for i in range(len(X_shifted)):\n",
    "    shift = np.random.choice([-4, 4])  # Randomly select a shift value between from -4 and 4\n",
    "    X_shifted[i] = np.roll(X_shifted[i], shift, axis=1)  # Shift the image horizontally\n",
    "X_train  = np.copy(X_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Display Random Images of the shifted Dataset\n",
    "Display random images from the training dataset in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display random images in a grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(5, 5))  # Create a 3x3 grid of subplots\n",
    "for i, ax in enumerate(axes.flat):  # Loop over the flattened array of axes\n",
    "    index = np.random.randint(0, X_train.shape[0])  # Select a random index from the training set\n",
    "    image = X_train[index]  # Get the image at the selected index\n",
    "    ax.imshow(image, cmap='gray')  # Display the image in grayscale\n",
    "    ax.set_title(f'Label: {y_train[index]}')  # Set the title of the subplot to the label of the image\n",
    "plt.tight_layout()  # Adjust the layout to minimize overlap of subplot elements\n",
    "plt.show()  # Display the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Flatten the Images\n",
    "Flatten the images in the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Create and Train the Neural Network Classifier\n",
    "Create a neural network classifier and train it on the flattened training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the neural network classifier\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_flat.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 44.5154 - accuracy: 0.3000\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.7893 - accuracy: 0.7133\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9643 - accuracy: 0.8483\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.9500\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9817\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9983\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 4.3904e-05 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4345e-05 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5384e-05 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7972e-05 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.4454e-05 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1868e-05 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9745e-05 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7978e-05 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6536e-05 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.5325e-05 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4274e-05 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3346e-05 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2651e-05 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.1878e-05 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1235e-05 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0657e-05 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0084e-05 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9.5896e-06 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.1478e-06 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.7607e-06 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.3635e-06 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8.0349e-06 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.6865e-06 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.3874e-06 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 7.1029e-06 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.8431e-06 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.6143e-06 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.3819e-06 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.1572e-06 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.9536e-06 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.7567e-06 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.5782e-06 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.4006e-06 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.2401e-06 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.0754e-06 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.9292e-06 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.7897e-06 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.6580e-06 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.5297e-06 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4059e-06 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.3008e-06 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.1844e-06 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0787e-06 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.9780e-06 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.8819e-06 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.7871e-06 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6931e-06 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6117e-06 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5276e-06 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.4470e-06 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3755e-06 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.2970e-06 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3.2225e-06 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 3.1522e-06 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0856e-06 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0189e-06 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9581e-06 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.8967e-06 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.8405e-06 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7850e-06 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.7234e-06 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.6766e-06 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.6267e-06 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5750e-06 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5295e-06 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4787e-06 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4322e-06 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3929e-06 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3444e-06 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3060e-06 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2639e-06 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2212e-06 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1874e-06 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1467e-06 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1092e-06 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.0742e-06 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.0378e-06 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0084e-06 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9709e-06 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9401e-06 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9111e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1623a72f160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model.fit(X_train_flat, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  Evaluate accuracy on the train and train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Train Accuracy: 1.0\n",
      "Neural Network Test Accuracy: 0.1899999976158142\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set\n",
    "train_accuracy_nn = model.evaluate(X_train_flat, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Train Accuracy: {train_accuracy_nn}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy_nn = model.evaluate(X_test_flat, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Test Accuracy: {test_accuracy_nn}\")  # Print the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.  Standardize the Data\n",
    "Standardize the flattened training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "# StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)  # Fit to data, then transform it.\n",
    "X_test_scaled = scaler.transform(X_test_flat)  # Perform standardization by centering and scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.  Create and Train the Neural Network Classifier on Scaled Data\n",
    "Create a neural network classifier and train it on the standardized training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 1.8498 - accuracy: 0.3933\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7097 - accuracy: 0.8483\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9283\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9783\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9917\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.9000e-04 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.4313e-04 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.9832e-04 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.5922e-04 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.1983e-04 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.8262e-04 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.4914e-04 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.1766e-04 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.9065e-04 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.5943e-04 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.3248e-04 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.0686e-04 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.8471e-04 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.6204e-04 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.4139e-04 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.2259e-04 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.0253e-04 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.8456e-04 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.6740e-04 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.5133e-04 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.3651e-04 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.2164e-04 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0780e-04 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.9454e-04 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.8227e-04 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6957e-04 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5827e-04 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.4755e-04 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3670e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2647e-04 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.1709e-04 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0775e-04 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9861e-04 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9053e-04 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.8195e-04 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7426e-04 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.6656e-04 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.5958e-04 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5231e-04 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4602e-04 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3927e-04 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3308e-04 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.2689e-04 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2141e-04 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1557e-04 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1040e-04 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0507e-04 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0014e-04 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9514e-04 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.9048e-04 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8592e-04 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8162e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16233373640>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the neural network classifier on scaled data\n",
    "model_scaled = Sequential()\n",
    "model_scaled.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n",
    "\n",
    "model_scaled.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model_scaled.fit(X_train_scaled, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.  Evaluate Classifier Accuracy on Scaled Data\n",
    "Evaluate the accuracy of the classifier on the standardized training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Scaled Train Accuracy: 1.0\n",
      "Neural Network Scaled Test Accuracy: 0.28999999165534973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set using scaled data\n",
    "train_accuracy_nn_scaled = model_scaled.evaluate(X_train_scaled, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Scaled Train Accuracy: {train_accuracy_nn_scaled}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set using scaled data\n",
    "test_accuracy_nn_scaled = model_scaled.evaluate(X_test_scaled, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Scaled Test Accuracy: {test_accuracy_nn_scaled}\")  # Print the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.  Apply Min-Max Scaling to the Data\n",
    "Apply min-max scaling to the flattened training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scaling\n",
    "# MinMaxScaler transforms features by scaling each feature to a given range.\n",
    "scaler = MinMaxScaler()\n",
    "# Apply min-max scaling to the training data\n",
    "X_train_mmscaled = scaler.fit_transform(X_train_flat)\n",
    "# Apply min-max scaling to the test data\n",
    "X_test_mmscaled = scaler.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.  Create and Train the Neural Network Classifier on Min-Max Scaled Data\n",
    "Create a neural network classifier and train it on the min-max scaled training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 1s 3ms/step - loss: 2.0209 - accuracy: 0.3433\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2355 - accuracy: 0.7233\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.8633\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.9200\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9467\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9800\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9883\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9967\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9967\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.9066e-04 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.5586e-04 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.1592e-04 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.8293e-04 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.4989e-04 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.1858e-04 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.9320e-04 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.6422e-04 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.3538e-04 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.1122e-04 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.8698e-04 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.6594e-04 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.4140e-04 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.2006e-04 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.0167e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5.8214e-04 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.6572e-04 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.4838e-04 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.3064e-04 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.1637e-04 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.0012e-04 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.8593e-04 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.7203e-04 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.5918e-04 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4531e-04 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.3386e-04 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.2129e-04 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0930e-04 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.9974e-04 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.8822e-04 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.7772e-04 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.6823e-04 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.5873e-04 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.4956e-04 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.4135e-04 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3267e-04 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2408e-04 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.1578e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162367402e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the neural network classifier on scaled data\n",
    "model_scaled = Sequential()\n",
    "model_scaled.add(Dense(128, activation='relu', input_shape=(X_train_mmscaled.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n",
    "model_scaled.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model_scaled.fit(X_train_mmscaled, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.  Evaluate Classifier Accuracy on Min-Max Scaled Data\n",
    "Evaluate the accuracy of the classifier on the min-max scaled training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Scaled Train Accuracy: 1.0\n",
      "Neural Network Scaled Test Accuracy: 0.23999999463558197\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set using scaled data\n",
    "train_accuracy_nn_scaled = model_scaled.evaluate(X_train_mmscaled, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Scaled Train Accuracy: {train_accuracy_nn_scaled}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set using scaled data\n",
    "test_accuracy_nn_scaled = model_scaled.evaluate(X_test_mmscaled, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Scaled Test Accuracy: {test_accuracy_nn_scaled}\")  # Print the test accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

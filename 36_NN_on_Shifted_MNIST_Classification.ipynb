{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "Import the necessary libraries, including matplotlib, keras, numpy, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Subset MNIST Dataset\n",
    "Load the MNIST dataset and create a subset for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of subset training data: 600\n",
      "Length of subset testing data: 100\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Create a new subset dataset\n",
    "subset_train_indices = []\n",
    "subset_test_indices = []\n",
    "for class_label in range(10):\n",
    "    class_indices = np.where(y_train == class_label)[0]\n",
    "    subset_train_indices.extend(class_indices[:60])\n",
    "    class_indices = np.where(y_test == class_label)[0]\n",
    "    subset_test_indices.extend(class_indices[60:70])\n",
    "\n",
    "X_train = X_train[subset_train_indices]\n",
    "y_train = y_train[subset_train_indices]\n",
    "X_test = X_test[subset_test_indices]\n",
    "y_test = y_test[subset_test_indices]\n",
    "\n",
    "# Display the length of each part\n",
    "print(f\"Length of subset training data: {len(X_train)}\")\n",
    "print(f\"Length of subset testing data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Dataset Information\n",
    "Display the length of the subset training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of class 0 in training data: 60\n",
      "Sum of class 1 in training data: 60\n",
      "Sum of class 2 in training data: 60\n",
      "Sum of class 3 in training data: 60\n",
      "Sum of class 4 in training data: 60\n",
      "Sum of class 5 in training data: 60\n",
      "Sum of class 6 in training data: 60\n",
      "Sum of class 7 in training data: 60\n",
      "Sum of class 8 in training data: 60\n",
      "Sum of class 9 in training data: 60\n",
      "Sum of class 0 in testing data: 10\n",
      "Sum of class 1 in testing data: 10\n",
      "Sum of class 2 in testing data: 10\n",
      "Sum of class 3 in testing data: 10\n",
      "Sum of class 4 in testing data: 10\n",
      "Sum of class 5 in testing data: 10\n",
      "Sum of class 6 in testing data: 10\n",
      "Sum of class 7 in testing data: 10\n",
      "Sum of class 8 in testing data: 10\n",
      "Sum of class 9 in testing data: 10\n",
      "Length of subset training data: 600\n",
      "Length of subset testing data: 100\n"
     ]
    }
   ],
   "source": [
    "# Print the sum of each class label in the training data\n",
    "for i in range(10):\n",
    "    print(f\"Sum of class {i} in training data: {sum(y_train == i)}\")\n",
    "\n",
    "# Print the sum of each class label in the testing data\n",
    "for i in range(10):\n",
    "    print(f\"Sum of class {i} in testing data: {sum(y_test == i)}\")\n",
    "\n",
    "# Display the length of each part\n",
    "print(f\"Length of subset training data: {len(X_train)}\")\n",
    "print(f\"Length of subset testing data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Images in Dataset\n",
    "Randomly shift the images in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Images in Dataset\n",
    "X_shifted = np.copy(X_train)\n",
    "for i in range(len(X_shifted)):\n",
    "    shift = np.random.choice([-4, 4])  # Randomly select a shift value between from -4 and 4\n",
    "    X_shifted[i] = np.roll(X_shifted[i], shift, axis=1)  # Shift the image horizontally\n",
    "X_train  = np.copy(X_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Random Images of the shifted Dataset\n",
    "Display random images from the training dataset in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display random images in a grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(5, 5))  # Create a 3x3 grid of subplots\n",
    "for i, ax in enumerate(axes.flat):  # Loop over the flattened array of axes\n",
    "    index = np.random.randint(0, X_train.shape[0])  # Select a random index from the training set\n",
    "    image = X_train[index]  # Get the image at the selected index\n",
    "    ax.imshow(image, cmap='gray')  # Display the image in grayscale\n",
    "    ax.set_title(f'Label: {y_train[index]}')  # Set the title of the subplot to the label of the image\n",
    "plt.tight_layout()  # Adjust the layout to minimize overlap of subplot elements\n",
    "plt.show()  # Display the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the Images\n",
    "Flatten the images in the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train the Neural Network Classifier\n",
    "Create a neural network classifier and train it on the flattened training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the neural network classifier\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_flat.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 39.3070 - accuracy: 0.2933\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.2998 - accuracy: 0.6483\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1869 - accuracy: 0.8567\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 994us/step - loss: 0.4495 - accuracy: 0.9417\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 925us/step - loss: 0.1521 - accuracy: 0.9683\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 924us/step - loss: 0.0870 - accuracy: 0.9833\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9933\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5440e-04 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9983\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4363e-04 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.3837e-05 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0862e-05 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5761e-05 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2169e-05 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0353e-05 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8721e-05 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 984us/step - loss: 1.7353e-05 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 937us/step - loss: 1.6264e-05 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 926us/step - loss: 1.5292e-05 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 896us/step - loss: 1.4430e-05 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 927us/step - loss: 1.3750e-05 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 922us/step - loss: 1.3002e-05 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 924us/step - loss: 1.2475e-05 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1894e-05 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1465e-05 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0980e-05 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0584e-05 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0192e-05 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.8239e-06 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.5125e-06 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.1793e-06 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.8782e-06 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.6221e-06 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.3599e-06 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.1211e-06 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.8824e-06 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 927us/step - loss: 7.6714e-06 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.4565e-06 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 922us/step - loss: 7.2723e-06 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 928us/step - loss: 7.0729e-06 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 926us/step - loss: 6.9076e-06 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.7159e-06 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.5633e-06 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.4038e-06 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.2478e-06 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.1118e-06 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.9616e-06 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.8344e-06 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.7085e-06 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.5942e-06 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.4647e-06 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.3398e-06 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.2392e-06 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.1296e-06 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.0282e-06 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.9202e-06 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.8294e-06 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.7324e-06 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.6488e-06 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.5576e-06 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4642e-06 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.3832e-06 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 897us/step - loss: 4.3089e-06 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.2266e-06 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.1525e-06 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.0792e-06 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0095e-06 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.9346e-06 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.8732e-06 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.8037e-06 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.7423e-06 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6791e-06 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6183e-06 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5593e-06 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5068e-06 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 3.4463e-06 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3.3964e-06 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3390e-06 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 3.2891e-06 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2400e-06 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.1888e-06 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.1405e-06 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0902e-06 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 3.0457e-06 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0020e-06 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9547e-06 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9110e-06 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.8729e-06 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.8286e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acf5933fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model.fit(X_train_flat, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy on the train and train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Train Accuracy: 1.0\n",
      "Neural Network Test Accuracy: 0.15000000596046448\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set\n",
    "train_accuracy_nn = model.evaluate(X_train_flat, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Train Accuracy: {train_accuracy_nn}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy_nn = model.evaluate(X_test_flat, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Test Accuracy: {test_accuracy_nn}\")  # Print the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the Data\n",
    "Standardize the flattened training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "# StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)  # Fit to data, then transform it.\n",
    "X_test_scaled = scaler.transform(X_test_flat)  # Perform standardization by centering and scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train the Neural Network Classifier on Scaled Data\n",
    "Create a neural network classifier and train it on the standardized training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9692 - accuracy: 0.3767\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 0.7994 - accuracy: 0.8100\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.9133\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9767\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9933\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9983\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 867us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.9564e-04 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.4683e-04 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.0242e-04 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 8.5900e-04 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.2103e-04 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.8322e-04 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.4808e-04 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.1661e-04 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 6.8755e-04 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 6.5764e-04 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.3175e-04 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.0641e-04 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.8305e-04 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.6103e-04 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.3929e-04 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.1902e-04 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.0064e-04 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.8193e-04 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.6483e-04 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4921e-04 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.3395e-04 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.1847e-04 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0477e-04 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.9177e-04 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.7883e-04 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6681e-04 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5539e-04 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.4389e-04 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3374e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2328e-04 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.1380e-04 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0422e-04 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9585e-04 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 867us/step - loss: 2.8701e-04 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7902e-04 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7089e-04 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.6296e-04 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5597e-04 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4915e-04 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4256e-04 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3597e-04 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2973e-04 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2368e-04 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1772e-04 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 2.1219e-04 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0707e-04 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0170e-04 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9675e-04 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9175e-04 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8719e-04 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 868us/step - loss: 1.8275e-04 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7827e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acf71c05b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the neural network classifier on scaled data\n",
    "model_scaled = Sequential()\n",
    "model_scaled.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n",
    "\n",
    "model_scaled.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model_scaled.fit(X_train_scaled, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classifier Accuracy on Scaled Data\n",
    "Evaluate the accuracy of the classifier on the standardized training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Scaled Train Accuracy: 1.0\n",
      "Neural Network Scaled Test Accuracy: 0.25999999046325684\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set using scaled data\n",
    "train_accuracy_nn_scaled = model_scaled.evaluate(X_train_scaled, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Scaled Train Accuracy: {train_accuracy_nn_scaled}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set using scaled data\n",
    "test_accuracy_nn_scaled = model_scaled.evaluate(X_test_scaled, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Scaled Test Accuracy: {test_accuracy_nn_scaled}\")  # Print the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Min-Max Scaling to the Data\n",
    "Apply min-max scaling to the flattened training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scaling\n",
    "# MinMaxScaler transforms features by scaling each feature to a given range.\n",
    "scaler = MinMaxScaler()\n",
    "# Apply min-max scaling to the training data\n",
    "X_train_mmscaled = scaler.fit_transform(X_train_flat)\n",
    "# Apply min-max scaling to the test data\n",
    "X_test_mmscaled = scaler.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train the Neural Network Classifier on Min-Max Scaled Data\n",
    "Create a neural network classifier and train it on the min-max scaled training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0597 - accuracy: 0.3217\n",
      "Epoch 2/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2538 - accuracy: 0.7200\n",
      "Epoch 3/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.8433\n",
      "Epoch 4/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8983\n",
      "Epoch 5/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.9283\n",
      "Epoch 6/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9683\n",
      "Epoch 7/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9850\n",
      "Epoch 8/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9950\n",
      "Epoch 9/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "19/19 [==============================] - 0s 968us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "19/19 [==============================] - 0s 945us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 9.6563e-04 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 9.3174e-04 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.9027e-04 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.5748e-04 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 8.2496e-04 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.9503e-04 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 7.6527e-04 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.3854e-04 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 7.1488e-04 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.8933e-04 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.6595e-04 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 6.4115e-04 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.2222e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.0092e-04 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.8153e-04 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.6492e-04 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.4594e-04 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 5.2835e-04 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.1215e-04 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.9639e-04 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.8257e-04 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.6737e-04 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.5442e-04 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.4091e-04 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.2955e-04 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 4.1724e-04 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 4.0411e-04 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.9411e-04 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.8356e-04 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 3.7234e-04 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6248e-04 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.5282e-04 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.4282e-04 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3425e-04 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2594e-04 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.1833e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acf9cb75b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the neural network classifier on scaled data\n",
    "model_scaled = Sequential()\n",
    "model_scaled.add(Dense(128, activation='relu', input_shape=(X_train_mmscaled.shape[1],)))  # First hidden layer with 128 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(64, activation='relu'))  # Second hidden layer with 64 neurons and ReLU activation function\n",
    "model_scaled.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons (one for each class) and softmax activation function\n",
    "model_scaled.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, cross-entropy loss function, and accuracy as the evaluation metric\n",
    "model_scaled.fit(X_train_mmscaled, y_train, epochs=90, batch_size=32, verbose=1)  # Train the model for 10 epochs with a batch size of 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classifier Accuracy on Min-Max Scaled Data\n",
    "Evaluate the accuracy of the classifier on the min-max scaled training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Scaled Train Accuracy: 1.0\n",
      "Neural Network Scaled Test Accuracy: 0.2800000011920929\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy on the train set using scaled data\n",
    "train_accuracy_nn_scaled = model_scaled.evaluate(X_train_mmscaled, y_train, verbose=0)[1]  # Evaluate the model on the training set\n",
    "print(f\"Neural Network Scaled Train Accuracy: {train_accuracy_nn_scaled}\")  # Print the training accuracy\n",
    "\n",
    "# Evaluate accuracy on the test set using scaled data\n",
    "test_accuracy_nn_scaled = model_scaled.evaluate(X_test_mmscaled, y_test, verbose=0)[1]  # Evaluate the model on the test set\n",
    "print(f\"Neural Network Scaled Test Accuracy: {test_accuracy_nn_scaled}\")  # Print the test accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
